{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766afc70-16a0-4b4f-a222-95bef0734c60",
   "metadata": {},
   "source": [
    "# Module 1, Activity 2: Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c801dc40-7069-4113-998b-a005cda6459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9a4fb8-8081-46da-9ce5-8840fe020bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd345d-c0b3-4d2c-9d99-de2db48ef0aa",
   "metadata": {},
   "source": [
    "## About this cell\n",
    "\n",
    "This is a helper function to download data from a file in an S3 bucket.  You can also make the connection directly, if you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044abfbc-05ce-4ef9-9e46-d03d8333528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_s3(bucket_name, key):\n",
    "    s3 = boto3.client('s3', region_name='us-west-2')\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    return response['Body'].read().decode('latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e8bbba-4761-4110-b794-78416a54c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BILL Reports Second Quarter Fiscal Year 2025 Financial Results\n",
      "February 6, 2025\n",
      "\n",
      "\t•\tQ2 Core Revenue Increased 16% Year-Over-Year\n",
      "\t•\tQ2 Total Revenue Increased 14% Year-Over-Year\n",
      "SAN JOSE, Calif.--(BUSINESS WIRE)-- BILL (NYSE: BILL), a leading financial operations platform for small and midsize businesses (SMBs), today announced financial results for the second fiscal quarter ended December 31, 2024.\n",
      "“We delivered strong financial results and innovated at a rapid pace as we executed on our vision\n"
     ]
    }
   ],
   "source": [
    "s3_data = get_data_from_s3(\"dpgenaitraining\", \"q2_results.txt\")\n",
    "print(s3_data[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8f87ee-d1e7-41fc-98f9-6191536f741e",
   "metadata": {},
   "source": [
    "## Zero-Shot Prompting\n",
    "\n",
    "We are now going to pass this text into the LLM and ask it to analyze it with varying degrees of instruction, as passed through the prompt.  \n",
    "\n",
    "The most basic type of prompting is called \"zero-shot prompting,\" which is when you provide the model with just the question or instruction and expect it to get the answer just based on its pre-trained knowledge.  No examples or additional context are provided.  Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16cf439-278b-4460-a78a-8b75784a694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"metric\": \"Gross profit\",\n",
      "    \"current\": \"$295.9 million\",\n",
      "    \"previous\": \"$260.1 million\",\n",
      "    \"difference\": \"$35.8 million\",\n",
      "    \"percentage_change\": \"13.8%\"\n",
      "  },\n",
      "  {\n",
      "    \"metric\": \"Total operating expenses\",\n",
      "    \"current\": \"$317.7 million\",\n",
      "    \"previous\": \"$327.8 million\",\n",
      "    \"difference\": \"-$10.1 million\",\n",
      "    \"percentage_change\": \"-3.1%\"\n",
      "  },\n",
      "  {\n",
      "    \"metric\": \"Net income\",\n",
      "    \"current\": \"$33.5 million\",\n",
      "    \"previous\": \"-$40.4 million\",\n",
      "    \"difference\": \"$73.9 million\",\n",
      "    \"percentage_change\": \"182.9%\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\"You are a helpful assistant.\")\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    #model_id=\"meta.llama4-maverick-17b-instruct-v1:0\",\n",
    "    region_name=region,\n",
    "    temperature=0.5,\n",
    "    max_tokens=25000000,\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "print(chain.invoke({\"input\": f\"Using the file  {s3_data}, extract year-over-year financial data for three metrics—gross profit, total operating expenses, and net income and calculate the differences and percentage changes. The output must be a JSON array where each element is an object containing the keys 'metric', 'current', 'previous', 'difference', and 'percentage_change'. Each value should be represented as a string with appropriate units (e.g., '100.0 million' or '10.0%'), and no additional text or separate JSON arrays should be included.\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd73031-2222-4979-ad6b-ba3b31e08456",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting\n",
    "\n",
    "While that did alright, we can do better if we can provide a few examples within the prompt to guide the model's behavior.  This is called \"few-shot prompting.\"  By demonstrating the format, style, or type of answer you expect, the model can better understand and mimic that structure in its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a44b805-153d-46ba-8edc-9f1355459458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Constitution of the United States is the foundational document that establishes the structure, powers, and principles of the federal government. It is one of the oldest written constitutions still in effect and has served as a model for many other nations. Here's an analysis of some key aspects of the U.S. Constitution:\n",
      "\n",
      "1. Separation of Powers: The Constitution divides the federal government into three branches - legislative, executive, and judicial - with distinct powers and responsibilities. This separation of powers creates a system of checks and balances to prevent any one branch from becoming too powerful.\n",
      "\n",
      "2. Federalism: The Constitution outlines the relationship between the federal government and state governments, allocating certain powers to the federal government while reserving other powers for the states. This system of federalism aims to balance national unity with state autonomy.\n",
      "\n",
      "3. Bill of Rights: The first ten amendments to the Constitution, known as the Bill of Rights, outline fundamental civil liberties and rights that the government cannot infringe upon, such as freedom of speech, religion, and the press, as well as due process and protection against unreasonable searches and seizures.\n",
      "\n",
      "4. System of Checks and Balances: The Constitution establishes a system of checks and balances among the three branches of government. For example, the President can veto legislation passed by Congress, but Congress can override a presidential veto with a two-thirds majority vote in both chambers.\n",
      "\n",
      "5. Amendment Process: The Constitution provides a mechanism for its own amendment, allowing for changes and adaptations to address evolving societal needs and circumstances. Amendments require a two-thirds vote in both houses of Congress and ratification by three-fourths of the states.\n",
      "\n",
      "6. Supremacy Clause: The Constitution establishes itself as the \"supreme law of the land,\" meaning that federal laws and treaties take precedence over state laws in cases of conflict.\n",
      "\n",
      "7. Flexibility and Interpretation: While the Constitution outlines the basic structure and principles of government, it is a relatively brief document that leaves room for interpretation and adaptation over time through judicial review and legislative action.\n",
      "\n",
      "The Constitution has proven to be a remarkably durable and influential document, balancing stability with the ability to adapt to changing circumstances. Its principles of limited government, individual rights, and checks and balances have shaped the American political system and served as a model for democratic nations worldwide.\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = f\"\"\"\n",
    "You are provided with {s3_data} and given the following:\n",
    "Example 1:\n",
    "Q: What is the significance of the Constitution of the United States?\n",
    "A: The Constitution is the supreme law of the United States...\n",
    "\n",
    "Example 2:\n",
    "Q: How does the Constitution implement checks and balances?\n",
    "A: It divides power among three branches...\n",
    "\n",
    "Now, answer the following:\n",
    "Q: Provide an analysis of the Constitution of the United States.\n",
    "A:\n",
    "\"\"\"\n",
    "print(chain.invoke({\"input\": few_shot_prompt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef87cefb-6763-4a0a-a78b-9992bdb882d9",
   "metadata": {},
   "source": [
    "## Chain-of-Thought (COT) Prompts\n",
    "\n",
    "Chain-of-thought prompting is a technique where you guide the model to break down its reasoning process into sequential steps before arriving at the final answer. Instead of generating a direct answer in one go, you instruct the model to \"think aloud\" by detailing intermediate steps.  This can lead to more thorough and accurate responses, especially for complex or multi-step problems.  It works particularly well with more sophisticated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da04f121-f852-4d0c-ad2e-26eb3a08e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have expertise in constitutional law to provide a detailed analysis on the structure of the U.S. Constitution, its system of checks and balances, and its modern legal influence. The document provided appears to be BILL Holdings Inc.'s Q2 2025 financial results, which does not contain information relevant to analyzing the U.S. Constitution from a legal perspective. As an AI assistant without specific training in this domain, I do not have the necessary knowledge to comprehensively examine constitutional matters as requested. I cannot provide a substantive response based on the given information.\n"
     ]
    }
   ],
   "source": [
    "cot_prompt = f\"\"\"\n",
    "You are an expert in constitutional law. You have been provided {s3_data}.\n",
    "Please analyze this data by following these steps:\n",
    "Step 1: Summarize the structure of the Constitution.\n",
    "Step 2: Explain the checks and balances.\n",
    "Step 3: Discuss its modern legal influence.\n",
    "\"\"\"\n",
    "print(chain.invoke({\"input\": cot_prompt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80c4625-b73a-4a9d-8b30-d45b464907f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm afraid I don't have enough context to determine what specific subject we previously discussed. I don't actually have a long-term memory of our prior conversation. Could you please provide me with some more details about the topic you're referring to?\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"input\": \"What subject did we just discuss?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361183c9-b433-414e-a223-9ae744323bd5",
   "metadata": {},
   "source": [
    "## Oops!\n",
    "\n",
    "Notice that we just asked the LLM to tell us about what we have been talking about with it.  However, LLM's do not, by default, have any memory.  This is something we need to add to it by creating a chat history.\n",
    "\n",
    "_**Note:**_\n",
    "\n",
    "It is likely when you run the below cell you will get a deprecation error.  This is because LangChain is changing how they handle conversational memory, encouraging migration to their new platform, LangGraph.  LangGraph is a sophisticated platform used for the orchestration of multi-agent bots that use tools.  At this stage it is beyond the scope of where we are in this workshop but we will discuss it when we get to \"Module 4: Agents and Tool Use.\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f7d7c1-8018-4e3c-97d1-d8fe4dd2b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hk/x5jlwc1s6dx_w4j79wt6vr2w0000gp/T/ipykernel_49070/3972174010.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "/var/folders/hk/x5jlwc1s6dx_w4j79wt6vr2w0000gp/T/ipykernel_49070/3972174010.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_with_memory = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "system_prompt_mem = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Use the conversation history: {chat_history}\"\n",
    ")\n",
    "human_prompt_mem = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "prompt_mem = ChatPromptTemplate.from_messages([system_prompt_mem, human_prompt_mem])\n",
    "\n",
    "chain_with_memory = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_mem,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f0f018-d4fe-4923-a986-2ab35d726ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a basic recipe for making mayonnaise from scratch:\n",
      "\n",
      "Ingredients:\n",
      "- 1 egg yolk\n",
      "- 1 tablespoon lemon juice or white wine vinegar\n",
      "- 1/2 teaspoon dijon mustard (optional, but helps emulsify)\n",
      "- 1/4 teaspoon salt\n",
      "- 3/4 cup vegetable oil or mild olive oil\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. In a medium bowl, whisk together the egg yolk, lemon juice/vinegar, mustard (if using), and salt.\n",
      "\n",
      "2. Very slowly, while whisking constantly, drizzle in a few drops of the oil until the mixture begins to thicken and emulsify.\n",
      "\n",
      "3. Still whisking constantly, drizzle in the remaining oil a few drops at a time until fully incorporated and the mayonnaise is thick.\n",
      "\n",
      "4. Once all the oil is incorporated, you can whisk a bit more rapidly to get the desired thick, creamy texture.\n",
      "\n",
      "5. Taste and adjust seasoning if needed by adding more lemon juice, salt, etc.\n",
      "\n",
      "6. Transfer to an airtight container and refrigerate for up to 1 week.\n",
      "\n",
      "The key is adding the oil very slowly while whisking vigorously to allow a stable emulsion to form between the egg yolk and oil. Be patient during this step.\n"
     ]
    }
   ],
   "source": [
    "response1 = chain_with_memory.invoke(\"What is the recipe for mayonnaise?\")\n",
    "print(response1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d87c2d2-83b0-44df-a1b1-8f3793859286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked me for the recipe for mayonnaise.\n"
     ]
    }
   ],
   "source": [
    "response2 = chain_with_memory.invoke(\"What recipe did I just ask you for?\")\n",
    "print(response2['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e614b-d6f1-4ed9-a221-9a2935feecd9",
   "metadata": {},
   "source": [
    "## Best Practices for Prompt Engineering\n",
    "\n",
    "Notice that we used statements like \"you are an expert in...\"  Informing the LLM how they should respond within the prompt is considered to be good prompt engineering practice.  But there are many other things you should consider adding to your prompts.  Here are some general guidelines taken from [this website](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api):\n",
    "\n",
    "- Use the latest models (noting that many popular models are updated regularly...be sure you have the most recent version)\n",
    "- Put the instructions at the beginning of the prompt and use delimiters like `####` or `\"\"\"\"` to separate the instruction and context.\n",
    "- Be specific, descriptive, and as detailed as possible about the desired context, outcome, length, format, style, etc.\n",
    "- Articulate the desired output format through examples\n",
    "- When possible, do not use imprecise descriptions\n",
    "- Don't just say what NOT to do...say what to do instead\n",
    "\n",
    "AWS also has a great guide on prompt engineering with the Titan models that can be found [here](https://d2eo22ngex1n9g.cloudfront.net/Documentation/User+Guides/Titan/Amazon+Titan+Text+Prompt+Engineering+Guidelines.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114404bc-ec56-4684-aceb-ecaf76d66918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
